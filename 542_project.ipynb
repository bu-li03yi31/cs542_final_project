{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cs542 Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborator: Yiteng Xu, Changlei Shi, ChenCheng Wang, Yi Li"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def readJson(f):\n",
    "    for l in open(f):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "items = []\n",
    "\n",
    "for l in open(\"anonymous-msweb.data\"):\n",
    "    if l.startswith(\"A\"):\n",
    "        m,n,p,q,i = l.strip().split(',')\n",
    "        q = q[1:-1]\n",
    "        i = i[1:-1]\n",
    "        tmp = [n, q, i]\n",
    "        items.append(tmp)\n",
    "\n",
    "items_df = pd.DataFrame(items)\n",
    "items_df.to_csv(\"item.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nw = csv.writer(open(\"user_item_dict.csv\", \"w\"))\\nfor key, val in training_user_item_dict.items():\\n    w.writerow([key, val])\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current = \"\"\n",
    "item = \"\"\n",
    "user_item = []\n",
    "training_user_item_dict = {}\n",
    "\n",
    "for l in open(\"anonymous-msweb.data\"):\n",
    "    if l.startswith(\"C\"):\n",
    "        m,n,p = l.strip().split(',')\n",
    "        current = p\n",
    "    if l.startswith(\"V\"):\n",
    "        a,b,c = l.strip().split(',')\n",
    "        item = b\n",
    "        tp = [current, item]\n",
    "        user_item.append(tp)\n",
    "        if current in training_user_item_dict:\n",
    "            cur_list = training_user_item_dict[current]\n",
    "            cur_list.append(item)\n",
    "            training_user_item_dict[current] = cur_list\n",
    "        else:\n",
    "            my_list = [item]\n",
    "            training_user_item_dict[current] = my_list\n",
    "user_item_df = pd.DataFrame(user_item)\n",
    "user_item_df.to_csv(\"user_item.txt\")\n",
    "\n",
    "json_str = json.dumps(training_user_item_dict)\n",
    "data = json.loads(json_str)\n",
    "with open('user_item_dict.json', 'w') as f:\n",
    "    json.dump(data, f)\n",
    "#print training_user_item_dict\n",
    "'''\n",
    "w = csv.writer(open(\"user_item_dict.csv\", \"w\"))\n",
    "for key, val in training_user_item_dict.items():\n",
    "    w.writerow([key, val])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "items = []\n",
    "\n",
    "for l in open(\"anonymous-msweb.test\"):\n",
    "    if l.startswith(\"A\"):\n",
    "        m,n,p,q,i = l.strip().split(',')\n",
    "        q = q[1:-1]\n",
    "        i = i[1:-1]\n",
    "        tmp = [n, q, i]\n",
    "        items.append(tmp)\n",
    "\n",
    "items_df = pd.DataFrame(items)\n",
    "items_df.to_csv(\"item_test.txt\")\n",
    "\n",
    "current = \"\"\n",
    "item = \"\"\n",
    "user_item = []\n",
    "training_user_item_dict = {}\n",
    "for l in open(\"anonymous-msweb.test\"):\n",
    "    if l.startswith(\"C\"):\n",
    "        m,n,p = l.strip().split(',')\n",
    "        current = p\n",
    "    if l.startswith(\"V\"):\n",
    "        a,b,c = l.strip().split(',')\n",
    "        item = b\n",
    "        tp = [current, item]\n",
    "        user_item.append(tp)\n",
    "        if current in training_user_item_dict:\n",
    "            cur_list = training_user_item_dict[current]\n",
    "            cur_list.append(item)\n",
    "            training_user_item_dict[current] = cur_list\n",
    "        else:\n",
    "            my_list = [item]\n",
    "            training_user_item_dict[current] = my_list\n",
    "user_item_df = pd.DataFrame(user_item)\n",
    "user_item_df.to_csv(\"user_item_test.txt\")\n",
    "\n",
    "#print training_user_item_dict\n",
    "json_str = json.dumps(training_user_item_dict)\n",
    "data = json.loads(json_str)\n",
    "with open('user_item_dict_test.json', 'w') as f:\n",
    "    json.dump(data, f)\n",
    "\n",
    "'''\n",
    "w = csv.writer(open(\"user_item_dict_test.csv\", \"w\"))\n",
    "for key, val in training_user_item_dict.items():\n",
    "    w.writerow([key, val])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "count = 1000\n",
    "columnName = []\n",
    "while count <= 1297:\n",
    "    columnName.append(count)\n",
    "    count = count + 1\n",
    "\n",
    "with open('user_item_dict.json') as data_file:    \n",
    "    compare_users_data = json.load(data_file)\n",
    "    \n",
    "big_matrix = []\n",
    "index = []\n",
    "for attribute, value in compare_users_data.iteritems():\n",
    "    index.append(attribute)\n",
    "    tmp_arr = np.zeros(298)\n",
    "    for element in value:\n",
    "        #print element\n",
    "        tmp_arr[int(element) - 1000] = 1\n",
    "    big_matrix.append(tmp_arr)\n",
    "\n",
    "big_matrix_df = pd.DataFrame(big_matrix)\n",
    "big_matrix_df.columns = columnName\n",
    "big_matrix_df.index = index\n",
    "print big_matrix_df[1008][11542]\n",
    "big_matrix_df.to_csv(\"big_matrix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14478\n",
      "[\"'1136'\", \" '1046'\", \" '1018'\"]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "dict = {}\n",
    "for key, val in csv.reader(open(\"user_item_dict_test.csv\")):\n",
    "    print key\n",
    "    val[1:-1].replace('\\'', '')\n",
    "    print str(val[1:-1]).split(\",\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Memory-based Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.01592736388\n",
      "32711\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "#load file\n",
    "user_item_df = pd.read_csv(\"user_item.txt\")\n",
    "user_item_df.columns = ['index','user', 'item']\n",
    "user_item_df.drop('index', axis=1, inplace=True)\n",
    "\n",
    "#group by user and get the total vote of each user\n",
    "tmp = user_item_df.groupby(['user']).count()\n",
    "user_votes = []\n",
    "for index, item in tmp.iterrows():\n",
    "    c = int(item['item'])\n",
    "    tp = [index, c]\n",
    "    user_votes.append(tp)\n",
    "\n",
    "#save results to another dataframe\n",
    "user_votes_df = pd.DataFrame(user_votes)\n",
    "user_votes_df.columns = ['user','count']\n",
    "\n",
    "#print the mean of votes per user\n",
    "print user_votes_df['count'].mean()\n",
    "#print number of users in trainning set\n",
    "print len(user_votes_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import OrderedDict\n",
    "from operator import itemgetter\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import defaultdict\n",
    "    \n",
    "def prediction(user_a, item_j, compare_users_data, alpha):\n",
    "    tmp = {}\n",
    "    for user_i in compare_users_data:\n",
    "        _list = compare_users_data[user_i]\n",
    "        if user_a is not user_i and len(_list) > alpha:\n",
    "            v_ij = 0\n",
    "            if item_j in _list:\n",
    "                v_ij = 1\n",
    "            w = getWeight2(user_a, user_i, compare_users_data)\n",
    "            tmp[user_i] = w\n",
    "    \n",
    "    sorted_tmp = sorted(tmp.iteritems(), key=itemgetter(1), reverse=True)\n",
    "    nearest_neighbour = [sorted_tmp[0][0], sorted_tmp[1][0],sorted_tmp[2][0],sorted_tmp[3][0],sorted_tmp[4][0],sorted_tmp[5][0],sorted_tmp[6][0],sorted_tmp[7][0],sorted_tmp[8][0]]\n",
    "    \n",
    "    W = 0\n",
    "    total = 0\n",
    "    big_list = []\n",
    "    for user in nearest_neighbour:\n",
    "        _list = compare_users_data[user]\n",
    "        big_list = big_list + _list\n",
    "    if item_j in list(set(big_list)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "\n",
    "def getWeight(a, i, compare_users_data):\n",
    "    set1 = set(compare_users_data[a])\n",
    "    set2 = set(compare_users_data[i])\n",
    "    length1 = len(set1)\n",
    "    length2 = len(set2)\n",
    "    inter = set1.intersection(set2)\n",
    "    den1 = math.sqrt(length1)\n",
    "    den2 = math.sqrt(length2)\n",
    "    res = float(len(inter)) / (den1 * den2)\n",
    "    return res\n",
    "\n",
    "def getWeight2(a, i, compare_users_data):\n",
    "    set1 = set(compare_users_data[a])\n",
    "    set2 = set(compare_users_data[i])\n",
    "    union = set1.union(set2)\n",
    "    inter = set1.intersection(set2)\n",
    "    res = float(len(inter)) / len(union)\n",
    "    return res\n",
    "\n",
    "with open('user_item_dict.json') as data_file:    \n",
    "    compare_users_data = json.load(data_file)\n",
    "\n",
    "print prediction(\"10077\",\"1004\",compare_users_data,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha is 4: \n",
      "0.528141662827\n",
      "\n",
      "\n",
      "Alpha is 6: \n",
      "0.624580343625\n",
      "\n",
      "\n",
      "Alpha is 9: \n",
      "0.715621091436\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def KNNTest(alpha):\n",
    "    f_file = \"user_item_test.txt\"\n",
    "    total = 0\n",
    "    count = 0\n",
    "    for l in open(f_file):\n",
    "        if l.startswith(\",\"):\n",
    "            continue\n",
    "        a = l.split(\",\")\n",
    "        user = a[1]\n",
    "        item = a[2].rstrip('\\n')\n",
    "        total = total + 1\n",
    "        res = prediction(user, item,compare_users_data,alpha)\n",
    "        if res == 1:\n",
    "            count = count + 1\n",
    "        \n",
    "    return float(count) / total\n",
    "\n",
    "print 'Alpha is 4: '\n",
    "print KNNTest(4)\n",
    "print '\\n'\n",
    "\n",
    "print 'Alpha is 6: '\n",
    "print KNNTest(6)\n",
    "print '\\n'\n",
    "\n",
    "print 'Alpha is 9: '\n",
    "print KNNTest(9)\n",
    "print '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for setting the style of the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test for Bayesian Models classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.989932885906\n",
      "0.010067114094\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "big_matrix = pd.read_csv('big_matrix.csv',index_col = 0)\n",
    "\n",
    "row = 10001\n",
    "column = '1000'\n",
    "#print big_matrix[column][row]\n",
    "\n",
    "assume_0 = 0\n",
    "assume_1 = 1\n",
    "\n",
    "\n",
    "prior_0 = float((big_matrix == 0).astype(int).sum(axis=1)[row]) / 298\n",
    "prior_1 = float((big_matrix == 1).astype(int).sum(axis=1)[row]) / 298\n",
    "print prior_0\n",
    "print prior_1\n",
    "#print big_matrix[1038][10001]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '../../theme/custom.css'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d44b2fe746ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstyles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../theme/custom.css\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcss_styling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-d44b2fe746ba>\u001b[0m in \u001b[0;36mcss_styling\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcss_styling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mstyles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../theme/custom.css\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcss_styling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '../../theme/custom.css'"
     ]
    }
   ],
   "source": [
    "\n",
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"../../theme/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
